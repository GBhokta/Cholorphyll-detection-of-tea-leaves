{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LEIeQ5BByrJ",
        "outputId": "50e9c1b9-f4c0-4180-a929-1ff3a7e44774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial data preview:\n",
            "       mean_r      mean_g      mean_b   stddev_r   stddev_g   stddev_b  \\\n",
            "0  197.478470  203.192213  191.790658  55.235822  42.422848  68.479752   \n",
            "1  157.704656  161.870731  154.137681  52.779257  44.960307  61.544117   \n",
            "2  168.650369  172.254505  162.291823  55.136258  46.913445  64.705274   \n",
            "3  153.039775  155.967225  148.876568  53.016721  45.475238  61.839672   \n",
            "4  186.557493  190.859075  182.166241  59.816635  50.340256  70.457058   \n",
            "\n",
            "      variance    stddv_h    stddv_s    stddv_v  kurtosis  skewness  Chl Value  \n",
            "0  3201.722811  39.823970  65.016452  42.536723  2.693144 -2.003428       42.9  \n",
            "1  2874.905799  45.798970  72.509849  45.350869  1.417275 -1.547380       44.6  \n",
            "2  3159.514270  50.383784  72.455308  47.207545  1.618314 -1.658600       44.9  \n",
            "3  2909.436115  65.195754  76.502124  46.150734  1.320430 -1.581516       45.3  \n",
            "4  3704.717453  51.364393  70.523119  50.726218  2.146370 -1.901518       45.2  \n",
            "\n",
            "Data summary:\n",
            "            mean_r       mean_g       mean_b     stddev_r     stddev_g  \\\n",
            "count  1500.000000  1500.000000  1500.000000  1500.000000  1500.000000   \n",
            "mean    163.173775   167.120321   157.062333    43.778474    35.681186   \n",
            "std      36.154286    36.554225    35.788697    12.851595    10.540126   \n",
            "min       2.259592     2.846533     1.241938    16.045376    12.751508   \n",
            "25%     154.771287   157.368650   149.996794    33.494795    27.720100   \n",
            "50%     170.668908   175.287528   164.782762    44.825860    35.475005   \n",
            "75%     181.489201   186.629348   174.744123    53.268765    42.832792   \n",
            "max     208.403165   212.272332   202.984726    75.522077    65.061582   \n",
            "\n",
            "          stddev_b     variance      stddv_h      stddv_s      stddv_v  \\\n",
            "count  1500.000000  1500.000000  1500.000000  1500.000000  1500.000000   \n",
            "mean     57.174429  2364.988872    48.118899    69.688218    36.482912   \n",
            "std      17.050112  1209.036924    10.794079    14.554460    11.228394   \n",
            "min      15.706908   251.771557     5.941523     2.954162    13.090083   \n",
            "25%      43.482843  1347.146488    42.623987    58.996057    28.023941   \n",
            "50%      60.375722  2359.307751    49.706921    70.587980    36.002233   \n",
            "75%      70.457058  3197.230915    54.690861    80.513912    43.716075   \n",
            "max      89.811038  5790.713337    83.723033   103.071839    75.383485   \n",
            "\n",
            "          kurtosis     skewness    Chl Value  \n",
            "count  1500.000000  1500.000000  1500.000000  \n",
            "mean      7.118900    -2.180285    35.221067  \n",
            "std      10.241016     1.698986     9.349187  \n",
            "min      -0.909649    -5.335713     9.000000  \n",
            "25%       1.798585    -3.009312    29.200000  \n",
            "50%       4.782312    -2.300531    34.250000  \n",
            "75%       9.768074    -1.658798    39.600000  \n",
            "max     156.224934    11.844060    73.700000  \n",
            "\n",
            "Null values in dataset:\n",
            "mean_r       0\n",
            "mean_g       0\n",
            "mean_b       0\n",
            "stddev_r     0\n",
            "stddev_g     0\n",
            "stddev_b     0\n",
            "variance     0\n",
            "stddv_h      0\n",
            "stddv_s      0\n",
            "stddv_v      0\n",
            "kurtosis     0\n",
            "skewness     0\n",
            "Chl Value    0\n",
            "dtype: int64\n",
            "\n",
            "MLR Model Performance:\n",
            "MAE: 3.700, MSE: 23.126, RMSE: 4.809, R²: 0.736\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "file_path = 'Dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "print(\"Initial data preview:\")\n",
        "print(data.head())\n",
        "data.describe()\n",
        "\n",
        "print(\"\\nData summary:\")\n",
        "print(data.describe())\n",
        "print(\"\\nNull values in dataset:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "\n",
        "X = data.drop(columns=[\"Chl Value\"])\n",
        "y = data[\"Chl Value\"]\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "mlr_model = LinearRegression()\n",
        "mlr_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = mlr_model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse ** 0.5\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"\\nMLR Model Performance:\")\n",
        "print(f\"MAE: {mae:.3f}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R²: {r2:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "X = data.drop(columns=[\"Chl Value\"])\n",
        "y = data[\"Chl Value\"]\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=X_train.shape[1], activation='relu'),  # Input layer\n",
        "    Dropout(0.2),  # Dropout to reduce overfitting\n",
        "    Dense(64, activation='relu'),  # Hidden layer\n",
        "    Dense(32, activation='relu'),  # Additional hidden layer\n",
        "    Dense(1, activation='linear')  # Output layer for regression\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
        "                    validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse ** 0.5\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f\"Test MAE: {mae:.3f}\")\n",
        "print(f\"Test MSE: {mse:.3f}\")\n",
        "print(f\"Test RMSE: {rmse:.3f}\")\n",
        "print(f\"Test R²: {r2:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SDQDzt7E7so",
        "outputId": "4e6fd4bf-d54a-433d-e876-e7562213177e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 1271.2651 - mae: 34.2355 - mse: 1271.2651 - val_loss: 998.9413 - val_mae: 29.6771 - val_mse: 998.9413\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 737.2759 - mae: 24.5538 - mse: 737.2759 - val_loss: 219.1593 - val_mae: 11.5796 - val_mse: 219.1593\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 195.5432 - mae: 11.2138 - mse: 195.5432 - val_loss: 142.2683 - val_mae: 9.2025 - val_mse: 142.2683\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 128.6195 - mae: 8.8404 - mse: 128.6195 - val_loss: 100.2102 - val_mae: 7.6419 - val_mse: 100.2102\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 98.3892 - mae: 7.7084 - mse: 98.3892 - val_loss: 73.7519 - val_mae: 6.6024 - val_mse: 73.7519\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 75.6368 - mae: 6.7564 - mse: 75.6368 - val_loss: 56.5335 - val_mae: 5.8409 - val_mse: 56.5335\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 65.4891 - mae: 6.1840 - mse: 65.4891 - val_loss: 45.0403 - val_mae: 5.2658 - val_mse: 45.0403\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.1563 - mae: 5.7695 - mse: 56.1563 - val_loss: 38.3501 - val_mae: 4.8658 - val_mse: 38.3501\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.0147 - mae: 5.0561 - mse: 43.0147 - val_loss: 33.2849 - val_mae: 4.4872 - val_mse: 33.2849\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.3459 - mae: 4.8392 - mse: 39.3459 - val_loss: 30.7989 - val_mae: 4.3321 - val_mse: 30.7989\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.6479 - mae: 4.6717 - mse: 39.6479 - val_loss: 28.3986 - val_mae: 4.1299 - val_mse: 28.3986\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.4199 - mae: 4.4349 - mse: 35.4199 - val_loss: 27.1412 - val_mae: 4.0323 - val_mse: 27.1412\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.7440 - mae: 4.5426 - mse: 36.7440 - val_loss: 25.7691 - val_mae: 3.9294 - val_mse: 25.7691\n",
            "Epoch 14/100\n",
            "\u001b[1m18/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.6663 - mae: 4.3269 - mse: 32.6663 "
          ]
        }
      ]
    }
  ]
}